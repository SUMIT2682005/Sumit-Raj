# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q0D_tbN66L6MJ0jkFwznRWqhfZ-WWJgq
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import grad
import matplotlib.pyplot as plt
import numpy as np

# Problem parameters
L = 0.5
H = 2.0
u_inlet = 5.0
rho = 1.06
mu = 0.04
p_out = 0

# Calculation of dp_dx
dp_dx = - (2 * mu * u_inlet) / (H**2)

# Calculate inlet pressure based on DP_DX and P_OUT
p_in = p_out - dp_dx * L

print(f"Calculated Pressure Gradient (DP_DX): {dp_dx:.4f}")
print(f"Pipe Length (L): {L:.2f} m")
print(f"Assumed Outlet Pressure (P_out): {p_out:.4f} Pa")
print(f"Calculated Inlet Pressure (P_in): {p_in:.4f} Pa")

# Neural Network and Training Parameters
NUM_PDE_POINTS = 2000 # Number of collocation points for PDE loss
NUM_DATA_POINTS = 5  # Number of random data points from analytical solution
epochs = 20000 # Increased epochs for better convergence with new parameters
Layers = [1, 50, 50, 50, 1]

# Set random seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Define analytical solution
def analytical_solution(y, H, mu, dp_dx):
    return (1 / (2 * mu)) * dp_dx * (y**2 - H**2)

class PINN(nn.Module):
    def __init__(self, layers):
        super(PINN, self).__init__()
        self.hidden_layers = nn.ModuleList()
        self.activation = nn.Tanh() # Tanh is a common activation for PINNs

        # Create layers
        for i in range(len(layers) - 2):
            self.hidden_layers.append(nn.Linear(layers[i], layers[i+1]))
        self.output_layer = nn.Linear(layers[-2], layers[-1])

    def forward(self, x):
        for layer in self.hidden_layers:
            x = self.activation(layer(x))
        x = self.output_layer(x)
        return x

def pde_loss(model, y_pde, mu, dp_dx):
    y_pde.requires_grad_(True)
    u_pred = model(y_pde)
    du_dy = grad(u_pred, y_pde, create_graph=True, grad_outputs=torch.ones_like(u_pred))[0]
    d2u_dy2 = grad(du_dy, y_pde, create_graph=True, grad_outputs=torch.ones_like(du_dy))[0]
    pde_residual = d2u_dy2 - (1 / mu) * dp_dx
    return torch.mean(pde_residual**2)

def bc_loss(model, H):
    y_wall_neg = torch.tensor([-H], dtype=torch.float32).reshape(-1, 1)
    y_wall_pos = torch.tensor([H], dtype=torch.float32).reshape(-1, 1)
    u_pred_neg = model(y_wall_neg)
    u_pred_pos = model(y_wall_pos)
    target_neg = torch.tensor([0.0], dtype=torch.float32).reshape(-1, 1)
    target_pos = torch.tensor([0.0], dtype=torch.float32).reshape(-1, 1)
    loss_neg = torch.mean((u_pred_neg - target_neg)**2)
    loss_pos = torch.mean((u_pred_pos - target_pos)**2)
    return loss_neg + loss_pos

# --- New: Data Loss Function ---
def data_loss(model, y_data, u_data_target):
    u_pred_data = model(y_data)
    return torch.mean((u_pred_data - u_data_target)**2)

# Training Setup
model = PINN(Layers)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Generate PDE collocation points
y_pde_points = torch.rand(NUM_PDE_POINTS, 1) * (2 * H) - H
y_pde_points = y_pde_points.float()

# --- New: Generate 5 random data points and their analytical values ---
# Generate random y-coordinates within the channel
y_data_random_np = (2 * H * np.random.rand(NUM_DATA_POINTS, 1)) - H
y_data_random_tensor = torch.tensor(y_data_random_np, dtype=torch.float32)

# Calculate analytical velocity at these random y-coordinates
u_data_target_np = analytical_solution(y_data_random_np, H, mu, dp_dx)
u_data_target_tensor = torch.tensor(u_data_target_np, dtype=torch.float32)

print("\n--- 5 Random Analytical Data Points Used for Training ---")
print(f"{'y-coordinate':<15} | {'Analytical u':<15}")
print("-" * 30)
for i in range(NUM_DATA_POINTS):
    print(f"{y_data_random_np[i, 0]:<15.4f} | {u_data_target_np[i, 0]:<15.4f}")
print("-" * 30)
# --- End of New Data Point Generation ---


# Training Loop
print("\nStarting PINN training...")
for epoch in range(epochs):
    optimizer.zero_grad()
    loss_pde = pde_loss(model, y_pde_points, mu, dp_dx)
    loss_bc = bc_loss(model, H) * 1000 # Increased weight for BCs
    loss_data = data_loss(model, y_data_random_tensor, u_data_target_tensor) * 1000 # Give data loss a high weight too

    total_loss = loss_pde + loss_bc + loss_data
    total_loss.backward()
    optimizer.step()

    if (epoch + 1) % 1000 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Total Loss: {total_loss.item():.8f}, '
              f'PDE Loss: {loss_pde.item():.8f}, BC Loss: {loss_bc.item():.8f}, '
              f'Data Loss: {loss_data.item():.8f}')

print("\nTraining finished.")

# Visualization of Results
y_test = torch.linspace(-H, H, 100).reshape(-1, 1)
model.eval()
with torch.no_grad():
    u_pred_pinn = model(y_test).numpy()

u_analytical = analytical_solution(y_test.numpy(), H, mu, dp_dx)

plt.figure(figsize=(10, 6))
plt.plot(u_analytical, y_test.numpy(), label='Analytical Solution', color='blue', linestyle='--')
plt.plot(u_pred_pinn, y_test.numpy(), label='PINN Prediction', color='red', marker='o', markersize=3, linestyle='-')
plt.xlabel('Velocity (u)')
plt.ylabel('Channel Height (y)')
plt.title(f'Fully Developed Laminar Flow in a 2D Channel\n(H={H}, U_max={u_inlet}, ρ={rho}, ν={mu}, L={L}m)\nwith {NUM_DATA_POINTS} Data Points')
plt.grid(True)
plt.legend()
plt.axvline(0, color='grey', linestyle=':', linewidth=0.8)
plt.axhline(0, color='grey', linestyle=':', linewidth=0.8)
plt.show()

# --- Comparison of PINN prediction at the specific 5 data points ---
print("\n--- Comparison of Analytical vs. PINN Predictions (The 5 Training Data Points) ---")
print(f"{'y-coordinate':<15} | {'Analytical u':<15} | {'PINN u':<15} | {'Absolute Error':<15}")
print("-" * 65)
with torch.no_grad():
    pinn_u_at_data_points = model(y_data_random_tensor).numpy()

for i in range(NUM_DATA_POINTS):
    y_val = y_data_random_np[i, 0]
    analytical_val = u_data_target_np[i, 0]
    pinn_val = pinn_u_at_data_points[i, 0]
    abs_error = np.abs(analytical_val - pinn_val)
    print(f"{y_val:<15.4f} | {analytical_val:<15.4f} | {pinn_val:<15.4f} | {abs_error:<15.8f}")
print("-" * 65)


# Create a 2D grid for pressure and velocity visualization
nx, ny = 100, 30 # More points in x-direction, fewer in y-direction
x = np.linspace(0, L, nx)
y = np.linspace(-H, H, ny)
X, Y = np.meshgrid(x, y)

# Predict velocity on the grid
with torch.no_grad():
    y_tensor = torch.tensor(Y.reshape(-1, 1), dtype=torch.float32)
    U_pred = model(y_tensor).numpy().reshape(ny, nx)

# Calculate pressure field based on the constant pressure gradient
P_pred = p_in + dp_dx * X

# Plot velocity contour with stretched x-axis and compressed y-axis
plt.figure(figsize=(12, 3)) # Wider and shorter figure
plt.subplot(1, 2, 1)
contour = plt.contourf(X, Y, U_pred, levels=20, cmap='jet')
plt.colorbar(contour, label='Velocity (m/s)', aspect=30) # Taller colorbar
plt.xlabel('Axial Position (x)')
plt.ylabel('Channel Height (y)')
plt.title('Velocity Field Prediction')
plt.gca().set_aspect(0.05) # Compress y-axis relative to x-axis (adjust this value as needed)

# Plot pressure contour with same aspect ratio
plt.subplot(1, 2, 2)
contour = plt.contourf(X, Y, P_pred, levels=20, cmap='jet')
plt.colorbar(contour, label='Pressure (Pa)', aspect=30)
plt.xlabel('Axial Position (x)')
plt.ylabel('Channel Height (y)')
plt.title('Pressure Field Prediction')
plt.gca().set_aspect(0.05) # Same aspect ratio as velocity plot

plt.tight_layout()
plt.show()